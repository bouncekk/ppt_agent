## 《智能体云原⽣开发》期末⼤作业 —— PPT内容扩展智能体

分工：       
**10235501442尹中成**：架构设计、LLMAgent设计、后端接口实现、实验文档。占比50%。       
**10235501407周雍佳**：docker容器化实现、前端搭建、实验文档、演示视频。占比50%。      
    
认可的评分方式：组内统一分数。     


## 一. 项目介绍：

本项目实现了一个面向课程复习场景的「PPT 内容扩展智能体」。  

典型使用流程如下：  

- 学生或老师在 Web 前端上传一份课程 PPT（支持本地文件上传与 URL 上传）；
- 后端解析 PPT，将每一页的标题、目录、要点等内容结构化为 `Slide` 对象；
- 系统对每一页内容进行向量化，并写入 Chroma 向量库，形成可语义检索的“长期记忆”；
- 学生在页面列表中选择某一页，或通过关键词进行语义搜索，后端基于向量检索召回相关页；
- LLM Agent 结合当前页、检索到的相关页面以及外部知识源（Arxiv 论文摘要等），生成结构化的「查漏补缺笔记」；
- 前端展示扩展后的 Markdown 笔记，支持左侧按页切换、右侧 Markdown 预览、复制原文以及导出为 PDF，。

整体目标是：在不改变原课件的前提下，为每一页 PPT 自动补充背景说明、公式推导、示例与延伸阅读建议，同时引入 Checklayer 与自评机制，尽可能控制 LLM 幻觉并对输出质量给出机器自评。   


## 二. 项目结构：  
  
项目目录如下：  

- `backend/`
  - `api.py`：FastAPI 入口，提供上传、检索、扩展生成、PDF 导出等 HTTP 接口；
- `core/`
  - `ppt_parser.py`：基于 `python-pptx` 的 PPT 解析模块，定义 `Slide` 结构；
  - `vector_store.py`：对 Chroma 向量库的封装，负责向量化与语义检索；
  - `llm_agent.py`：LLM Agent 与工具链封装，包含 Prompt 模板、Checklayer、自评设计等；
  - `external_knowledge.py`：外部知识检索工具，当前以 Arxiv 论文摘要为核心信息源，接口可扩展；
- `frontend/`
  - `upload.html`：主业务页面，集成 PPT 上传、页面列表、语义搜索与笔记展示；
  - `login.html` / `register.html`：简单登录注册页面；
  - `assets/app.js`：前端逻辑入口，封装与后端交互、页面状态管理与导出 PDF 等逻辑；
  - `assets/app.css`：样式文件。
- `sample_parsed_example.json`：示例化的解析结果，展示 `Slide` 在 JSON 中的落地形式，便于文档说明。
- `requirements.txt`：Python 依赖清单。
- `Dockerfile`、`docker-compose.yml`：容器化与本地云原生运行配置。


## 三. 技术选型
| 模块     | 选型                         |
| ------ | -------------------------- | 
| 后端框架   | FastAPI                    |
| LLM    | DeepSeek 云 API（deepseek-ai/DeepSeek-V3.2-Exp模型）          | 
| 向量库    | Chroma                     | 
| PPT 解析 | python-pptx | 
| 外部知识   |  Arxiv        | 
| 部署     | Docker + docker-compose    | 
| 协作     | GitHub + Actions           | 


**架构图**：
```
[ Frontend ]
     |
     v
[ Backend API (FastAPI) ]
     |
     |-- 文档解析模块 (PPT Parser)
     |
     |-- Embedding Service
     |       |
     |       v
     |   [ Vector DB (Chroma) ]
     |
     |-- LLM Agent
     |       |
     |       v
     |   [ Checklayer ]
     |       |
     |       v
     |   [ LLM API (DeepSeek) ]
     |
     |-- External Knowledge Tool
             |
             v
        [ Arxiv ]
```

- **技术原理**： 
Embedding ：嵌入模型用于将 PPT 中的文本内容映射到向量空间，使语义相近的知识点在向量空间中距离更近，从而支持基于语义的相关性检索。  
Vector DB ：向量数据库用于存储嵌入向量，并支持高效的相似度搜索，作为系统的长期语义记忆层，为智能体提供上下文支持，起到“防止 LLM 胡说”的作用。  
Checklayer ：在 LLM 输出前后增加的提示词级“自检层”，分为两步：先做 Self-consistency 检查，避免逻辑前后矛盾或同一内容反复出现；再对照内部检索结果与外部知识片段（Arxiv 等）进行事实校验，对不确定的结论明确标注“可能/待查证”，从而在不改变模型结构的前提下，尽量约束幻觉和低质量输出。

- **系统架构图说明**：
  已给出“前端 → FastAPI 后端 → 解析模块 / 向量库 / LLM Agent + Checklayer / 外部知识工具”的整体调用关系，体现出：各核心能力解耦为独立模块。

- **数据流向说明**：
  - 用户上传 PPT（或提供链接）到 Frontend；
  - Frontend 调用 Backend API，将 PPT 交给文档解析模块，抽取出页面、标题、要点等结构化数据；
  - Embedding Service 对解析后的切片生成向量并写入 Chroma 向量库；
  - 当用户选择某一页或发起扩展请求时，后端基于向量检索召回相关内容，交由 LLM Agent 结合 DeepSeek LLM 生成扩展讲解；
  - 生成结果先经过 Checklayer，对逻辑一致性、与检索结果/外部资料的匹配度进行校验与修正；
  - 通过 Checklayer 后的内容按页面返回给前端展示；
  - 如需延伸阅读或事实校验，Agent 通过 External Knowledge Tool 调用 Arxiv，补充相关参考资料。

- **云原⽣组件**：

  - 使用 `Dockerfile` 将 FastAPI 后端与核心依赖（`python-pptx`、Chroma、langchain-openai 等）打包为镜像；
  - 通过 `docker-compose.yml` 一次性启动后端服务与所需的本地资源（如持久化数据目录），简化开发与演示时的启动步骤；
  - 前端为纯静态页面，由 FastAPI 通过 `StaticFiles` 挂载在 `/ui` 路径下，天然适合以容器方式对外暴露；


## 四. LLM Agent 设计

### 工具链与模块划分

- **PPT 解析工具（`ppt_parser.py`）**：
  - 提供 `Slide` 数据结构（index、title、bullets、notes）。
  - `parse_ppt(path)`：基于 `python-pptx` 将 `.pptx` 解析为 `List[Slide]`。
  - `parse_ppt_to_json_file`：用于生成“PPT → JSON”的结构化输出样例。

- **Embedding / 检索工具（`vector_store.py`）**：
  - 封装 Chroma 向量库（存储于 `chroma_db/`）。
  - `slide_to_document(slide)`：将单页 `Slide` 拼接为用于向量化的文本。
  - `index_ppt_file(ppt_path, ppt_id)`：解析并写入向量库，形成内部检索索引。
  - `query_similar_slides(query_text, n_results)`：基于语义相似度返回相关页 ids、documents 与 metadatas。

- **外部知识工具（`external_knowledge.py`）**：
  - `search_external_knowledge(query, max_results)`：封装对外部权威知识源（当前以 Arxiv 论文搜索/摘要为主）的访问，根据查询语句返回若干条“【论文标题】+ 摘要”片段，作为延伸阅读与事实补充；

- **LLM Agent 与 Checklayer（`llm_agent.py`）**：
  - `AgentConfig`：
    - `use_wikipedia`：是否启用外部知识检索（由 `search_external_knowledge` 访问 Arxiv 等外部源）；
    - `top_k_slides`：内部向量检索召回的相关页数量；
    - `top_k_wiki`：Arxiv 外部知识召回的片段数量。
  - `build_slide_context_from_retrieval(slide, top_k)`：
    - 基于当前页标题在 Chroma 中做一次语义检索，
    - 将召回的相关页 index、title 与正文拼接为“内部上下文块”。
  - `expand_slide_with_tools(slide, config)`：
    - 调用内部检索与 `search_external_knowledge`，组装上下文；
    - 基于 Prompt 模板构造请求，最终通过 `call_llm` 访问 DeepSeek LLM；
  - `call_llm(prompt)`：
    - 使用 `langchain_openai.ChatOpenAI` 客户端，通过硅基流动的 OpenAI 兼容接口调用 `deepseek-ai/DeepSeek-V3.2-Exp`；
    - API Key、Base URL、模型名均通过环境变量 `SILICONFLOW_API_KEY`、`SILICONFLOW_BASE_URL`、`DEEPSEEK_MODEL` 配置，避免硬编码密钥；
    - 在网络不可达或配置异常时回退为“占位输出”，保证链路可演示。

### Prompt 模板与 Checklayer 设计

`build_prompt_for_slide_expansion` 将当前页 `Slide`、内部检索结果与外部知识片段组合为一个结构化 Prompt，核心结构如下：

- **输入信息块**：
  - 【当前 PPT 页面】：包含 index、title、bullets、notes；
  - 【PPT 内部相关页面（检索得到）】：由向量检索返回的相关页内容；
  - 【外部知识片段】：由 `search_external_knowledge` 返回的条目摘要。

- **输出目标**：
  - 要求 LLM 生成“扩展讲解笔记”，分为若干部分：
    1. 背景说明；
    2. 知识点详细解释（可含公式/关键步骤）；
    3. 示例（代码或生活类比）；
    4. 延伸阅读建议；
  - 输出格式为中文 Markdown，小标题分段。

- **Checklayer（提示词层面的两阶段设计）**：
  - 在 Prompt 开头显式要求模型先执行两步检查：
    1. **Self-consistency 检查**：对即将输出的要点、公式和示例代码进行自我审查，避免前后矛盾、逻辑不一致或同一段内容被多次重复；
    2. **事实与上下文校验**：对照“内部相关页面”和“外部知识片段”（Arxiv 等），检查关键结论是否明显违背上下文，对不确定内容标注“可能/待查证”，避免给出确定性的错误结论。

- **风格与安全约束**：
  - 强调与原 PPT 标题和要点保持语义一致，不偏题；
  - 如不确定某个细节，要求使用“可能”等措辞，而不是直接编造结论；
  - 明确要求“示例代码只给出一份，保持简洁，不要多次重复相同训练/预测语句或完全相同代码块”；
  - 要求优先参考内部检索结果与外部知识片段，避免产生明显“离谱”的内容。

## 五. 前端与交互设计

前端基于原生 HTML + TailwindCSS + 原生 JavaScript 实现，核心页面为 `frontend/upload.html`，主要交互流程如下：

- **登录 / 注册**：
  - 通过 `login.html` / `register.html` 与后端 `/auth/login`、`/auth/register` 接口交互；
  - 登录成功后本地保存 Token，并在后续请求中通过 `Authorization: Bearer <token>` 传递。

- **上传 PPT**：
  - 在“上传 PPT”区域支持两种方式：
    - 本地上传：选择 `.pptx` 文件，通过 `/upload` 上传；
    - URL 上传：输入可直链下载的 `.pptx` URL，通过 `/upload_url` 上传（支持 GitHub blob 链接自动转 raw 链接）。
  - 上传阶段前端显示进度条和状态提示，上传成功后展示 `ppt_id` 与页数。

- **页面列表与扩展生成**：
  - 右侧“页面列表”通过 `/slides` 接口获取指定 `ppt_id` 下的所有页面标题与要点；
  - 用户可以：
    - 点击“生成该页”，调用 `/expand` 为单页生成查漏补缺笔记；
    - 点击“一键生成整份查漏补缺笔记”，顺序为所有页面调用 `/expand` 并实时更新进度。

- **查漏补缺笔记区域**：
  - 左侧为“笔记页列表”，按页索引展示已生成的扩展笔记标题；
  - 右侧为 Markdown 预览区域，使用 `marked.min.js` 将后端返回的 Markdown 渲染为 HTML；
  - 同时维护一个隐藏的 `textarea` 存储原始 Markdown 文本，用于复制与导出。

- **复制与导出 PDF**：
  - “复制”按钮：从隐藏的 `textarea` 中读取 Markdown 原文，通过浏览器剪贴板 API 写入粘贴板；
  - “导出 PDF”按钮：基于 `html2pdf.js`，对当前预览区域的 HTML 内容进行截图并生成白底黑字的 A4 PDF。

- **语义搜索**：
  - 在“语义搜索”区域输入关键词，调用 `/search` 接口，在当前 `ppt_id` 内进行向量检索；
  - 返回的结果展示为“相关页 + 摘要”，用户可以直接在结果列表中点击“生成该页”触发 `/expand`。

整个前端逻辑集中在 `assets/app.js` 中，通过一套简易的状态管理（`pptId`、`slides`、`notesByIndex` 等）与 DOM 操作串联起上传、检索、生成和展示流程。

## 六. 异常处理

系统在多个关键路径上加入了基本的异常处理与用户提示，主要包括：

- **上传阶段**：
  - 本地上传：若未选择文件或文件后缀不是 `.pptx`，前端直接提示“请选择一个 .pptx 文件”；
  - URL 上传：
    - 若 URL 为空：提示“请填写 URL”；
    - 若 URL 后缀不是 `.pptx`：后端返回 400，提示“仅支持 .pptx 文件 URL”；
    - 若下载失败或内容无法解析为 PPTX（如非直链、跳转到 HTML 等），后端统一返回“URL 下载失败”或“下载的内容无法解析为 PPTX”，前端用红色错误框展示。

- **解析与向量化阶段**：
  - 若 `ppt_id` 未找到（如用户刷新页面后没有重新上传），访问 `/slides` 或 `/expand` 时后端返回 404，提示“ppt_id 未找到，请先上传 PPT”。

- **语义搜索阶段**：
  - 若用户未上传 PPT 就发起搜索，前端提示“请先上传 PPT”；
  - 若搜索关键词为空，提示“请输入搜索关键词”；
  - 若检索结果为空，前端展示“未检索到结果”。

- **LLM 调用与外部知识检索**：
  - 在没有配置 `SILICONFLOW_API_KEY` 等环境变量时，`call_llm` 会返回占位输出，保证链路可运行，并在提示中说明“请在部署环境中配置 API Key”；
  - 在网络错误或第三方接口异常时，`call_llm` 捕获异常并返回降级文案，避免接口直接崩溃。

- **PDF 导出阶段**：
  - 当当前笔记为空时点击“导出 PDF”，按钮会提示“内容为空”，不会生成空文件；
  - 若浏览器不支持或脚本 加载失败，会提示“浏览器不支持”或“导出失败”。

## 七. 补充
工程架构的    
**稳定性**：通过输入校验、错误码设计、前端友好提示以及将 PDF 导出前移到浏览器，降低了服务端故障风险，保证了核心流程的可用性。   
**扩展性**：模块边界清晰，LLM、向量库和外部知识源均以可替换的方式封装，为后续在模型、存储和知识源上的升级预留了空间。  



